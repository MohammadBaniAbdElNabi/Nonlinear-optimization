#  **Summary**

Nonlinear optimization models are used for mathematical programming problems in which the objective function and constraints are not necessarily linear. This class of problems is very broad, encompassing a wide variety of applications and approaches to solving the problems. No single algorithm applies equally to all nonlinear problems; instead, special algorithms have been developed that are effective on certain types of problems.<br>
Unconstrained optimization can often be dealt with through the use of calculus to find maximum and minimum points of a function. Constrained optimization typically requires solving systems of equations. As helpful as the mathematical theories are that can be used to describe the characteristics of optimal solutions to nonlinear problems, such insights nevertheless often fail to suggest computationally practical methods for actually finding the desired solutions.<br>
Iterative search techniques are frequently used for nonlinear optimization. A onedimensional search suffices for finding the optimum value of a function of one variable; at each step, the slope, or derivative, of the function is used to guide and restrict the search. Although such a technique seems much too elementary for a realistic nonlinear optimization problem, single-variable search methods are often incorporated into more sophisticated **multi-variable search** procedures.<br>
For finding the optima of functions of many variables, gradient search methods are guided by the slope of the function with respect to each of the variables. At each step, the method follows the direction indicated by the sharpest improvement from the current point. For this reason, techniques that operate in this way are often referred to as steepest ascent methods. Straight-line searches can be improved upon by using Newton’s method, which is based on quadratic approximations to nonlinear functions.<br>
Constrained optimization methods differ depending on the nature of the constraints. The method of Lagrange multipliers is applicable to problems with equality constraints. For problems with inequality constraints, Karush−Kuhn−Tucker theory describes necessary and sufficient conditions for optimality and forms the foundation of general mathematical programming.<br>