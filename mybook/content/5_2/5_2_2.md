#  Multivariable Search: Gradient Method

If our objective is to maximize a function $f(x)$ where $x = (x_1, x_2, \dots, x_n)$, then the previous single-variable search is not applicable. Recalling the necessary and sufficient conditions for the optimality of a solution $x^*$, the necessary condition is that

$$\frac{\partial f}{\partial x_i} = 0 \quad \text{at } x = x^* \text{ for all } i = 1, \dots, n$$

and this is *sufficient* if $f(x)$ is also concave. So, it is tempting simply to approach the problem as being that of solving a system of n equations, setting all the partial derivatives equal to zero. This would allow us to find the stationary points by solving the equations $\nabla f(x) = 0$. However, $f(x)$ and its partial derivatives are general nonlinear functions, and unless this system of equations has some special structure, this system cannot be solved analytically. So again, we turn to the use of iterative methods. And while the one dimensional search technique does not apply directly, it does provide a framework for how to proceed.

In a one dimensional search, at each iteration we examined the derivative of the function in order to decide whether to increase or decrease the current approximation to $x^*$. There were only the two choices along one dimension. Now, in an n-dimensional search space, at each iteration there are infinitely many directions to change the current $(x_1, x_2, \dots, x_n)$, and we can examine the partial derivatives to choose to move in that direction that yields the fastest possible improvement in $f(x)$. Whereas in a one dimensional search, we tried to reach a point x at which $df(x)/dx = 0$, now our aim is ultimately to reach a point $x = (x_1, x_2, \dots, x_n)$ at which all the partial derivatives of $f(x)$ are equal to zero.

The method described here is known as the **gradient search** procedure. Recall that the gradient of a function $f(x)$ at a point $x = x'$ is:

$$\nabla f(x') = \left[ \frac{\partial f}{\partial x_1}, \frac{\partial f}{\partial x_2}, \dots, \frac{\partial f}{\partial x_n} \right]_{\text{at } x=x'}$$


and the gradient will be used here as an indication of the direction of the fastest rate of increase of the function $f(x)$, viewed from the point $x = x'$. The gradient method will generate successive points by repeatedly moving in the direction of the gradient at each point.

The next question is *how far to move* in the direction of the gradient. A move from an initial point $x^0$ all the way to a solution $x^*$ for which $\nabla f(x^*) = 0$ would involve a circuitous route that would require constant re-evaluation of the gradient along the way. Because this would be computationally unreasonable, our method will instead move in a *straight line* in the direction of the gradient, and the distance to the next point will be: *as long as $f(x)$ keeps increasing*. At that new point where $f(x)$ is no longer increasing, the gradient is re-evaluated to determine the next direction to move, a distance for the next move is determined, and the next point is computed. This process repeats until two successive points are essentially the same, or $\nabla f(x)$ is within numerical tolerance of zero at one of the points.

This approach bears a resemblance to the method one might follow when climbing a mountain. At a given point, look around and select the direction of **steepest ascent** in the terrain, and follow that direction until the path is no longer ascending. At this point, look around again and select the direction of steepest ascent, and continue to repeat this process until arriving at a point at which none of the surrounding terrain is ascending. Assuming the mountain is concave, the climber has now reached the peak.

This analogy is only a two variable case in which the two variables represent the horizontal plane and the function value represents the vertical height of the surface of the mountain. Let us now describe this **steepest ascent** process for maximizing an n-variable function.

An initial approximation $x^0$ is chosen, then successively a point $x^{i+1}$ is found from the current point $x^i$ as follows:

$$x^{i+1} = x^i + d^i \cdot \nabla f(x^i)$$

where $d^i$ specifies the distance to be moved in this iteration. The value of $d^i$ must be found so as to maximize the function $f$ at the new point; therefore, we wish to

$$\text{maximize } f(x^i + d^i \cdot \nabla f(x^i))$$

with respect to $d^i$. Because all the other variables are now playing the role of constants in this context, we actually are merely faced with the problem of maximizing a function of a single variable. For this, we can take the derivative with respect to $d^i$, set it equal to zero, and solve for $d^i$; or use a one dimensional search method such as described in **Section 5.2.1**. The multivariable steepest ascent algorithm can now be stated succinctly as follows.